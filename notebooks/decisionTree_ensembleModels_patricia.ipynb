{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a0256-787e-40f6-9cbd-a5c956bcd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train, y_train = data_loader.training_data\n",
    "X_val, y_val = data_loader.validation_data\n",
    "X_test, y_test = data_loader.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514a46c-6420-4ee6-84cc-a3c6f2b23d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the decision tree model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = decision_tree.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07f455-fe3d-4734-a45b-e6e6172b0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "#Visualize the decision tree model\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(decision_tree,\n",
    "               feature_names=X_train.columns, \n",
    "               class_names=[\"No Diabetes\", \"Diabetes\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f64ee-9608-4532-bfbd-c1ac86cc5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the random forest ensemble model\n",
    "#TODO Adjust max_depth to? random_state?\n",
    "random_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = random_forest.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cc51e-28e2-45e0-900d-102106e9e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the random forest model\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(random_forest,\n",
    "               feature_names=X_train.columns, \n",
    "               class_names=[\"No Diabetes\", \"Diabetes\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992184a-5e96-46e1-9d9a-fb4343a57f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Initialize baseline models \n",
    "#TODO How many neighbours n= ?\n",
    "#TODO Do I need probability=True\n",
    "classifiers = {\n",
    "    \"decision tree\": DecisionTreeClassifier(),\n",
    "    \"logisitc regression\": LogisticRegression(),\n",
    "    \"naive bayes\":GaussianNB(), \n",
    "    \"support vector machines\": SVC(probability=True), # SVM with probabilities for soft voting??\n",
    "    \"k-NN with n = 5\": KNeighborsClassifier(n_neighbors=1)\n",
    "}\n",
    "\n",
    "# Implement function to display accuracy as performance metric for different classifiers\n",
    "#TODO habe y_val genommen nicht y_test ?\n",
    "def evaluate_classifier(e_name, e, X_train, y_train, X_val, y_val):\n",
    "    y_pred = e.fit(X_train, y_train).predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f'{e_name}: ACC={acc:.2f}')\n",
    "\n",
    "# Evaluate the classifiers' accuracies\n",
    "for e_name, e in classifiers.items():\n",
    "    evaluate_classifier(e_name, e, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf863581-7709-44a1-943d-a8f922d97a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Use bagging ensemble method as classifier\n",
    "bagging_classifiers = {f'{e_name} (B)': BaggingClassifier(e) for e_name, e in classifiers.items()}\n",
    "classifiers.update(bagging_classifiers)\n",
    "\n",
    "# Evaluate the classifiers' accuracies\n",
    "for e_name, e in classifiers.items():\n",
    "    evaluate_classifier(e_name, e, X_train, y_train, X_val, y_val) #TODO changed _test to _val, ok ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834342b5-03c5-42dd-88bc-878489ea13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Use boosting ensemble methods as classifiers\n",
    "classifiers['AdaBoost'] = AdaBoostClassifier()\n",
    "classifiers['XGBoost'] = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Evaluate the classifiers' accuracies\n",
    "for e_name, e in classifiers.items():\n",
    "    evaluate_classifier(e_name, e, X_train, y_train, X_val, y_val) #TODO changed _test to _val, ok ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfbf9b-f5e6-47f0-8f6d-e7c0edc2d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimator = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561d1b4-3987-47f0-99cd-367171f1b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use voting ensemble method as classifier\n",
    "#TODO random_states = ? und weights = ?\n",
    "voting = VotingClassifier(\n",
    "    (\"lr\", LogisticRegression(),\n",
    "     \"nb\",GaussianNB(), \n",
    "     \"svm\", SVC(probability=True), # SVM with probabilities for soft voting\n",
    "     \"knn_5\" KNeighborsClassifier(n_neighbors=5),                            \n",
    "     \"dt\", DecisionTreeClassifier())  \n",
    "    voting='soft', weights=[1, 2, 1]\n",
    ")\n",
    "\n",
    "#TODO Complete voting\n",
    "#TODO Evaluate the classifiers' accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d313945-fecf-409c-9733-ba2879b00c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Stacking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
