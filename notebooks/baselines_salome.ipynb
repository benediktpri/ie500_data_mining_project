{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train, y_train = data_loader.training_data\n",
    "X_val, y_val = data_loader.validation_data\n",
    "X_test, y_test = data_loader.test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority class for our dataset is \"no diabetes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.842439293598234\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91     21371\n",
      "         1.0       0.00      0.00      0.00      3997\n",
      "\n",
      "    accuracy                           0.84     25368\n",
      "   macro avg       0.42      0.50      0.46     25368\n",
      "weighted avg       0.71      0.84      0.77     25368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the support vector machine model\n",
    "baseline_majority = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "baseline_majority.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_majority = baseline_majority.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_majority = accuracy_score(y_val, y_val_pred_majority)\n",
    "report_majority = classification_report(y_val, y_val_pred_majority)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_majority}\")\n",
    "print(\"Classification Report:\\n\", report_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.842439293598234\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91     21371\n",
      "         1.0       0.00      0.00      0.00      3997\n",
      "\n",
      "    accuracy                           0.84     25368\n",
      "   macro avg       0.42      0.50      0.46     25368\n",
      "weighted avg       0.71      0.84      0.77     25368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# same as majority class, just with distributions\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the support vector machine model\n",
    "baseline_prior = DummyClassifier(strategy=\"prior\")\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "baseline_prior.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_prior = baseline_prior.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_prior = accuracy_score(y_val, y_val_pred_prior)\n",
    "report_prior = classification_report(y_val, y_val_pred_prior)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_prior}\")\n",
    "print(\"Classification Report:\\n\", report_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7375433617155471\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.85      0.84     21371\n",
      "         1.0       0.16      0.16      0.16      3997\n",
      "\n",
      "    accuracy                           0.74     25368\n",
      "   macro avg       0.50      0.50      0.50     25368\n",
      "weighted avg       0.74      0.74      0.74     25368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the support vector machine model\n",
    "baseline_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "baseline_stratified.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_stratified = baseline_stratified.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_stratified = accuracy_score(y_val, y_val_pred_stratified)\n",
    "report_stratified = classification_report(y_val, y_val_pred_stratified)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_stratified}\")\n",
    "print(\"Classification Report:\\n\", report_stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Use feature with highest correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature that has the highest correlation with our target (diabetes) is GenHealth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to have same accuracy as the baselines before. So redundant? Why include or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.842439293598234\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91     21371\n",
      "         1.0       0.00      0.00      0.00      3997\n",
      "\n",
      "    accuracy                           0.84     25368\n",
      "   macro avg       0.42      0.50      0.46     25368\n",
      "weighted avg       0.71      0.84      0.77     25368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# print(X_train.head())\n",
    "# type(X_train) # dataframe\n",
    "\n",
    "# TODO: train parameter: automatically:\n",
    "#       ... find value with highest correlation (e.g., GenHlth)\n",
    "#       ... find threshold (e.g., 0.3)\n",
    "\n",
    "X_train_GenHlth = X_train[['GenHlth']]\n",
    "\n",
    "def train_with_one_feature(X_train, y_train):\n",
    "    # Calculate correlation of each feature in X_train with y_train\n",
    "    correlations = X_train.apply(lambda x: x.corr(y_train))\n",
    "    \n",
    "    # Find the feature with the highest correlation\n",
    "    most_correlated_feature = correlations.idxmax()\n",
    "    \n",
    "    # Find threshold\n",
    "    threshold = 0.3 # TODO if we include this classifier\n",
    "    \n",
    "    return most_correlated_feature, threshold\n",
    "\n",
    "most_correlated_feature, threshold = train_with_one_feature(X_train, y_train)\n",
    "\n",
    "def predict_with_one_feature(df, feature, threshold):\n",
    "    y_hat = pd.DataFrame({\n",
    "        'Target': df[feature].apply(lambda x: 1 if x < threshold else 0)\n",
    "    })\n",
    "    return y_hat\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_one_feature = predict_with_one_feature(X_val, most_correlated_feature, threshold)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_one_feature = accuracy_score(y_val, y_val_pred_one_feature)\n",
    "report_one_feature = classification_report(y_val, y_val_pred_one_feature)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_one_feature}\")\n",
    "print(\"Classification Report:\\n\", report_one_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: First component of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this too good for a baseline? Should we use another (more dummy) classifier than K-NN for this first PCA component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8059\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89     21370\n",
      "         1.0       0.16      0.06      0.08      3998\n",
      "\n",
      "    accuracy                           0.81     25368\n",
      "   macro avg       0.50      0.50      0.49     25368\n",
      "weighted avg       0.74      0.81      0.76     25368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Apply PCA to reduce dimensions (you can choose the number of components, here it's set to 2 for visualization)\n",
    "pca = PCA(n_components=1)  # just the first component (it's a baseline)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_val)\n",
    "\n",
    "# copy from exercise 5\n",
    "def predict_knn(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Initialize the K-NN classifier (with k=5, you can adjust the number of neighbors)\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Measure performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Output results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "predict_knn(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
