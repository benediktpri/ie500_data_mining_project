{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train, y_train = data_loader.training_data\n",
    "X_val, y_val = data_loader.validation_data\n",
    "X_test, y_test = data_loader.test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Save model to pkl file for later reuse\n",
    "def save_model (model, model_name):\n",
    "    # Get the current timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Save the best model to a file with a timestamp\n",
    "    model_filename = f'../models/baseline/baseline_model_{model_name}_{timestamp}.pkl'\n",
    "    joblib.dump(model, model_filename)\n",
    "\n",
    "    print(f\"Initial model saved to '{model_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Baselines are on the unsampled, whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"most frequent\": Always picks the most common class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority class for our dataset is \"no diabetes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8423961352657005\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91     21797\n",
      "         1.0       0.00      0.00      0.00      4078\n",
      "\n",
      "    accuracy                           0.84     25875\n",
      "   macro avg       0.42      0.50      0.46     25875\n",
      "weighted avg       0.71      0.84      0.77     25875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Salome Heckenthaler\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Initialize the support vector machine model\n",
    "baseline_majority = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "baseline_majority.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_majority = baseline_majority.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_majority = accuracy_score(y_val, y_val_pred_majority)\n",
    "report_majority = classification_report(y_val, y_val_pred_majority)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_majority}\")\n",
    "print(\"Classification Report:\\n\", report_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model saved to '../models/baseline/baseline_model_majority_20241129_225242.pkl'\n"
     ]
    }
   ],
   "source": [
    "save_model(baseline_majority, \"majority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another standard baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"stratified\": Makes random guesses based on the original class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is in our case: \n",
    "Predicts no-diabetes with a probability of 218334/253680 = 0.86\n",
    "and diabetes with a probability of 35346/253680 = 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7394396135265701\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.85      0.85     21797\n",
      "         1.0       0.17      0.16      0.16      4078\n",
      "\n",
      "    accuracy                           0.74     25875\n",
      "   macro avg       0.51      0.50      0.51     25875\n",
      "weighted avg       0.74      0.74      0.74     25875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the support vector machine model\n",
    "baseline_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "# Train the model on the preprocessed training data\n",
    "baseline_stratified.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_stratified = baseline_stratified.predict(X_val)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_stratified = accuracy_score(y_val, y_val_pred_stratified)\n",
    "report_stratified = classification_report(y_val, y_val_pred_stratified)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_stratified}\")\n",
    "print(\"Classification Report:\\n\", report_stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Distribution baseline has a lower accuracy than the Majority Class baseline. But for the positive class (i.e., diabetes) precision, recall and f1-score are significantly higher, because they are 0 for Majority Class. Correspondingly, recall and f1-score of the negative class (i.e., no-diabetes) decreased from the Majority Class to Distribution baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model saved to '../models/baseline/baseline_model_stratified_20241129_225334.pkl'\n"
     ]
    }
   ],
   "source": [
    "save_model(baseline_stratified, \"stratified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Use feature with highest correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature that has the highest correlation with our target (diabetes) is GenHealth (with 0.29). This correlation is still far below 0.5. Thus, we can be sure that it is no false predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the feature having the highest correlation with our target (diabetes). \n",
    "Then, we calculate the mean of the target variable for each the ordinal values for that selected feature.\n",
    "Where we find the highest difference/gap between these means, we put our decision boundary.\n",
    "For this feature's values below that decision boundary, diabetes is predicted.\n",
    "For this feature's values above that decision boundary, no diabetes is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most correlated feature: GenHlth\n",
      "Means (grouped by class): {1.0: 0.031711541489529205, 2.0: 0.08568687030225491, 3.0: 0.20092068122833273, 4.0: 0.342883087400681, 5.0: 0.4081849274678618}\n",
      "Indices of the largest gap: (3.0, 4.0)\n",
      "\n",
      "Validation Accuracy: 0.7940483091787439\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88     21797\n",
      "         1.0       0.36      0.40      0.38      4078\n",
      "\n",
      "    accuracy                           0.79     25875\n",
      "   macro avg       0.62      0.63      0.63     25875\n",
      "weighted avg       0.80      0.79      0.80     25875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate correlation of each feature in X_train with y_train\n",
    "correlations = X_train.apply(lambda x: x.corr(y_train))\n",
    "# Find the feature with the highest correlation\n",
    "most_correlated_feature = correlations.idxmax()\n",
    "print(f\"Most correlated feature: {most_correlated_feature}\")\n",
    "    \n",
    "# Get unique values of this feature\n",
    "unique_values = X_train[most_correlated_feature].dropna().unique()\n",
    "means = {}\n",
    "\n",
    "# Combine X_train and y_train into a single DataFrame\n",
    "combined_df = pd.concat([X_train, y_train.rename('y_train')], axis=1)\n",
    "# Rename negative labels from 0 to -1\n",
    "\n",
    "# Group by the unique values in the specified column and calculate the mean of y_train\n",
    "# Get correlation with GenHlth for each of its values\n",
    "for unique_val in unique_values:\n",
    "    #correlations = combined_df[genhlth_dummies.columns].corrwith(combined_df['Diabetes_binary'])\n",
    "    subset = combined_df[combined_df[most_correlated_feature] == unique_val]\n",
    "    mu = subset['y_train'].mean()\n",
    "    means[unique_val] = mu\n",
    "\n",
    "# Sort dictionary of correlations increasingly by its key\n",
    "means = dict(sorted(means.items()))\n",
    "keys = list(means.keys())\n",
    "values = list(means.values())\n",
    "print(f\"Means (grouped by class): {means}\")\n",
    "\n",
    "# Find the largest gap\n",
    "largest_gap = 0\n",
    "indices_largest_gap = (None, None)\n",
    "for i in range(len(values) - 1):\n",
    "    gap = values[i+1] - values[i]\n",
    "    if gap > largest_gap:\n",
    "        largest_gap = gap\n",
    "        indices_largest_gap = (keys[i], keys[i+1])\n",
    "\n",
    "# Switch two values of largest gap \n",
    "# so that the first corresponds to no diabetes and the second to diabetes\n",
    "if means[indices_largest_gap[0]] > means[indices_largest_gap[1]]:\n",
    "    helper_switch = indices_largest_gap[0]\n",
    "    indices_largest_gap[0] = indices_largest_gap[1]\n",
    "    indices_largest_gap[1] = helper_switch\n",
    "print(f\"Indices of the largest gap: {indices_largest_gap}\\n\")\n",
    "\n",
    "# Make prediction on validation set\n",
    "y_val_pred_one_feature = pd.DataFrame({\n",
    "    'Target': X_val[most_correlated_feature].apply(lambda x: 1 if x >= indices_largest_gap[1] else 0)\n",
    "})\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_one_feature = accuracy_score(y_val, y_val_pred_one_feature)\n",
    "report_one_feature = classification_report(y_val, y_val_pred_one_feature)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_one_feature}\")\n",
    "print(\"Classification Report:\\n\", report_one_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Feature Evaluation on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most correlated feature: GenHlth\n",
      "Means (grouped by class): {np.float64(1.0): np.float64(0.031711541489529205), np.float64(2.0): np.float64(0.08568687030225491), np.float64(3.0): np.float64(0.20092068122833273), np.float64(4.0): np.float64(0.342883087400681), np.float64(5.0): np.float64(0.4081849274678618)}\n",
      "Indices of the largest gap: (np.float64(3.0), np.float64(4.0))\n",
      "\n",
      "Validation Accuracy: 0.7939636464990344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.87      0.88     42314\n",
      "         1.0       0.36      0.39      0.37      7915\n",
      "\n",
      "    accuracy                           0.79     50229\n",
      "   macro avg       0.62      0.63      0.63     50229\n",
      "weighted avg       0.80      0.79      0.80     50229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate correlation of each feature in X_train with y_train\n",
    "correlations = X_train.apply(lambda x: x.corr(y_train))\n",
    "# Find the feature with the highest correlation\n",
    "most_correlated_feature = correlations.idxmax()\n",
    "print(f\"Most correlated feature: {most_correlated_feature}\")\n",
    "    \n",
    "# Get unique values of this feature\n",
    "unique_values = X_train[most_correlated_feature].dropna().unique()\n",
    "means = {}\n",
    "\n",
    "# Combine X_train and y_train into a single DataFrame\n",
    "combined_df = pd.concat([X_train, y_train.rename('y_train')], axis=1)\n",
    "# Rename negative labels from 0 to -1\n",
    "\n",
    "# Group by the unique values in the specified column and calculate the mean of y_train\n",
    "# Get correlation with GenHlth for each of its values\n",
    "for unique_val in unique_values:\n",
    "    #correlations = combined_df[genhlth_dummies.columns].corrwith(combined_df['Diabetes_binary'])\n",
    "    subset = combined_df[combined_df[most_correlated_feature] == unique_val]\n",
    "    mu = subset['y_train'].mean()\n",
    "    means[unique_val] = mu\n",
    "\n",
    "# Sort dictionary of correlations increasingly by its key\n",
    "means = dict(sorted(means.items()))\n",
    "keys = list(means.keys())\n",
    "values = list(means.values())\n",
    "print(f\"Means (grouped by class): {means}\")\n",
    "\n",
    "# Find the largest gap\n",
    "largest_gap = 0\n",
    "indices_largest_gap = (None, None)\n",
    "for i in range(len(values) - 1):\n",
    "    gap = values[i+1] - values[i]\n",
    "    if gap > largest_gap:\n",
    "        largest_gap = gap\n",
    "        indices_largest_gap = (keys[i], keys[i+1])\n",
    "\n",
    "# Switch two values of largest gap \n",
    "# so that the first corresponds to no diabetes and the second to diabetes\n",
    "if means[indices_largest_gap[0]] > means[indices_largest_gap[1]]:\n",
    "    helper_switch = indices_largest_gap[0]\n",
    "    indices_largest_gap[0] = indices_largest_gap[1]\n",
    "    indices_largest_gap[1] = helper_switch\n",
    "print(f\"Indices of the largest gap: {indices_largest_gap}\\n\")\n",
    "\n",
    "# Make prediction on validation set\n",
    "y_val_pred_one_feature = pd.DataFrame({\n",
    "    'Target': X_test[most_correlated_feature].apply(lambda x: 1 if x >= indices_largest_gap[1] else 0)\n",
    "})\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_one_feature = accuracy_score(y_test, y_val_pred_one_feature)\n",
    "report_one_feature = classification_report(y_test, y_val_pred_one_feature)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_one_feature}\")\n",
    "print(\"Classification Report:\\n\", report_one_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ChatGPT, to transform it into a pkl file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "class OneFeatureModel:\n",
    "    def __init__(self, feature, threshold):\n",
    "        \"\"\"\n",
    "        Initialize with the selected feature and threshold.\n",
    "        \"\"\"\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels based on the feature and threshold.\n",
    "        \"\"\"\n",
    "        return X[self.feature].apply(lambda x: 1 if x >= self.threshold else 0)\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data.\n",
    "        \"\"\"\n",
    "        y_val_pred = self.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        report = classification_report(y_val, y_val_pred)\n",
    "        return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the feature and threshold from your script\n",
    "baseline_one_feature = OneFeatureModel(\n",
    "    feature=most_correlated_feature,\n",
    "    threshold=indices_largest_gap[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model saved to '../models/baseline/baseline_model_one_feature_20241129_230329.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a .pkl file\n",
    "save_model(baseline_one_feature, \"one_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.OneFeatureModel'>\n",
      "Validation Accuracy: 0.7940483091787439\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88     21797\n",
      "         1.0       0.36      0.40      0.38      4078\n",
      "\n",
      "    accuracy                           0.79     25875\n",
      "   macro avg       0.62      0.63      0.63     25875\n",
      "weighted avg       0.80      0.79      0.80     25875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO delete this cell, is just test/example\n",
    "\n",
    "# Load the model\n",
    "with open('../models/baseline/baseline_model_one_feature_20241129_230329.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Use the loaded model for prediction or evaluation\n",
    "y_val_pred_test = loaded_model.predict(X_val)\n",
    "accuracy_test, report_test = loaded_model.evaluate(X_val, y_val)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_test}\")\n",
    "print(\"Classification Report:\\n\", report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: KNN on First component of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this too good for a baseline? Should we use another (more dummy) classifier than K-NN for this first PCA component?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a conventional baseline, but since it is not overly complicated, it is suitable as a baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8167\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90     21797\n",
      "         1.0       0.26      0.09      0.13      4078\n",
      "\n",
      "    accuracy                           0.82     25875\n",
      "   macro avg       0.55      0.52      0.51     25875\n",
      "weighted avg       0.76      0.82      0.78     25875\n",
      "\n",
      "Explained variance by the first component: 0.4719632380321297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Apply PCA to reduce dimensions (you can choose the number of components, here it's set to 2 for visualization)\n",
    "pca = PCA(n_components=1)  # just the first component (it's a baseline)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "# Initialize the K-NN classifier (with k=5, you can adjust the number of neighbors)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_val_pca)\n",
    "\n",
    "# Measure performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Explained variance by the first component\n",
    "# = variance of that principal component / total variance\n",
    "# = variance of that principal component / sum of variances of all individual principal components\n",
    "explained_variance_ratio_first = pca.explained_variance_ratio_[0]\n",
    "print(f\"Explained variance by the first component: {explained_variance_ratio_first}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ChatGPT, to transform it into a pkl file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "\n",
    "class PCANNModel:\n",
    "    def __init__(self, n_components=1, n_neighbors=5):\n",
    "        \"\"\"\n",
    "        Initialize the PCA + KNN model.\n",
    "        \"\"\"\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit PCA and KNN on the training data.\n",
    "        \"\"\"\n",
    "        # Apply PCA\n",
    "        self.X_train_pca = self.pca.fit_transform(X_train)\n",
    "        # Train K-NN on the PCA-transformed data\n",
    "        self.knn.fit(self.X_train_pca, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for new data.\n",
    "        \"\"\"\n",
    "        # Transform data using PCA\n",
    "        X_pca = self.pca.transform(X)\n",
    "        # Predict using K-NN\n",
    "        return self.knn.predict(X_pca)\n",
    "\n",
    "    def evaluate(self, X, y_true):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred)\n",
    "        return accuracy, report\n",
    "\n",
    "    def explained_variance(self):\n",
    "        \"\"\"\n",
    "        Get the explained variance ratio of the PCA components.\n",
    "        \"\"\"\n",
    "        return self.pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "baseline_pca_nn = PCANNModel(n_components=1, n_neighbors=5)\n",
    "baseline_pca_nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8167\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90     21797\n",
      "         1.0       0.26      0.09      0.13      4078\n",
      "\n",
      "    accuracy                           0.82     25875\n",
      "   macro avg       0.55      0.52      0.51     25875\n",
      "weighted avg       0.76      0.82      0.78     25875\n",
      "\n",
      "Explained variance by the first component: 0.4720\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy, report = baseline_pca_nn.evaluate(X_val, y_val)\n",
    "explained_variance = baseline_pca_nn.explained_variance()\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(f\"Explained variance by the first component: {explained_variance[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/baseline/baseline_model_pca_nn_20241129_234922.pkl\n"
     ]
    }
   ],
   "source": [
    "# Get the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Save the model to a .pkl file\n",
    "with open(f'../models/baseline/baseline_model_pca_nn_{timestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(baseline_pca_nn, file)\n",
    "    print(\"Model saved to \" + f'../models/baseline/baseline_model_pca_nn_{timestamp}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8167\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90     21797\n",
      "         1.0       0.26      0.09      0.13      4078\n",
      "\n",
      "    accuracy                           0.82     25875\n",
      "   macro avg       0.55      0.52      0.51     25875\n",
      "weighted avg       0.76      0.82      0.78     25875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO delete this cell, is just test/example\n",
    "\n",
    "# Load the pipeline from the .pkl file\n",
    "with open('../models/baseline/baseline_model_pca_nn_20241129_234922.pkl', 'rb') as file:\n",
    "    loaded_model_2 = pickle.load(file)\n",
    "\n",
    "# Use the loaded pipeline for predictions\n",
    "y_pred = loaded_model_2.predict(X_val)\n",
    "\n",
    "# Evaluate the loaded model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in report: argue why it makes sense -> Explain/use/include the theory of PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we do not plot the explained variance of different numbers of principal components, because using any more than one component seems to be too much for a baseline that should be kept simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Majority class | Distribution | Highest correlation | KNN on 1st Principal Component |\n",
    "|----------|----------|----------|----------|----------|\n",
    "| Accuracy       | 0.84     | 0.74     | 0.79     | 0.82     |\n",
    "| Precision 0    | 0.84     | 0.84     | 0.89     | 0.85     |\n",
    "| Precision 1    | 0     | 0.15     | 0.36     | 0.26     |\n",
    "| Recall 0       | 1     | 0.85     | 0.87     | 0.95     |\n",
    "| Recall 1       | 0     | 0.14     | 0.40     | 0.09     |\n",
    "| F1 Score 0     | 0.91     | 0.84     | 0.88     | 0.90     |\n",
    "| F1 Score 1     | 0     | 0.15     | 0.38     | 0.13     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
