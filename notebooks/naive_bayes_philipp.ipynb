{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore various Naive Bayes classifiers to determine the most suitable one for our dataset. We begin by evaluating the performance of different Naive Bayes classifiers, including GaussianNB, CategoricalNB, and BernoulliNB, on the given training data. After identifying the best-performing classifier, we attempt to further improve the classification accuracy by using altered or partial training data.\n",
    "\n",
    "The steps involved in this notebook are as follows:\n",
    "1. **Initial Exploration**: Evaluate the performance of GaussianNB, CategoricalNB, and BernoulliNB classifiers on the training data.\n",
    "2. **Binary Feature Selection**: Focus on binary features to enhance the performance of the BernoulliNB classifier.\n",
    "3. **Hyperparameter Tuning**: Use GridSearchCV to find the optimal hyperparameters for the BernoulliNB classifier.\n",
    "4. **Dimensionality Reduction**: Apply Principal Component Analysis (PCA) to reduce the dimensionality of the dataset and evaluate the classifier's performance on the reduced data.\n",
    "5. **ROC Curve Analysis**: Plot ROC curves for different numbers of PCA components to visualize the classifier's performance.\n",
    "\n",
    "By following these steps, we aim to identify the most effective Naive Bayes classifier and optimize its performance for our specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train, y_train = data_loader.training_data\n",
    "X_val, y_val = data_loader.validation_data\n",
    "X_test, y_test = data_loader.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Initialize the classifier\n",
    "nb_classifier = CategoricalNB(alpha=1)\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Initialize the classifier\n",
    "nb_classifier = BernoulliNB(alpha=1)\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli Naive Bayes classifier achieves the highest accuracy (82.3%), followed by the Categorical Naive Bayes classifier (80.6%) and the Gaussian Naive Bayes classifier (76.8%). This outcome aligns with the nature of the training data: most features are either binary (14) or categorical (5), while only 2 features follow a normal distribution. Therefore, the Bernoulli classifier performs best, as it is specifically optimized for binary data. The Categorical Naive Bayes classifier also performs relatively well, as it is suited to categorical data, which is prevalent in this dataset. In contrast, the Gaussian Naive Bayes classifier, which assumes normally distributed features, achieves the lowest accuracy due to the limited number of features with a normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, these results are not really promising, as all classifiers except the Bernoulli classifier are worse than the naive classification of no diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can improve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features = [\n",
    "    \"HighBP\",\n",
    "    \"HighChol\",\n",
    "    \"CholCheck\",\n",
    "    \"Smoker\",\n",
    "    \"Stroke\",\n",
    "    \"HeartDiseaseorAttack\",\n",
    "    \"PhysActivity\",\n",
    "    \"Fruits\",\n",
    "    \"Veggies\",\n",
    "    \"HvyAlcoholConsump\",\n",
    "    \"AnyHealthcare\",\n",
    "    \"NoDocbcCost\",\n",
    "    \"DiffWalk\",\n",
    "    \"Sex\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the binary features\n",
    "X_train_binary = X_train[binary_features]\n",
    "\n",
    "# Initialize the classifier\n",
    "nb_classifier = BernoulliNB(alpha=1)\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_binary, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "X_val_binary = X_val[binary_features]\n",
    "y_val_pred = nb_classifier.predict(X_val_binary)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only binary features for the Bernoulli Naive Bayes classifier **increases** the performance slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparemeter tuning with all featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"alpha\": [0.1, 0.2, 0.3, 0.5, 1.0, 3.0, 4.0, 5.0],\n",
    "    \"fit_prior\": [True, False],\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "nb_classifier = BernoulliNB()\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=nb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=stratified_10_fold_cv,\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Perform the grid search on the binary features\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Use the best estimator to make predictions on the validation set\n",
    "best_nb_classifier = grid_search.best_estimator_\n",
    "y_val_pred = best_nb_classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy with Best Parameters: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparemeter tuning with only binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "nb_classifier = BernoulliNB()\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=nb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=stratified_10_fold_cv,\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Perform the grid search on the binary features\n",
    "grid_search.fit(X_train_binary, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Use the best estimator to make predictions on the validation set\n",
    "best_nb_classifier = grid_search.best_estimator_\n",
    "y_val_pred = best_nb_classifier.predict(X_val_binary)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy with Best Parameters: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Hyperparameter Tuning\n",
    "\n",
    "The hyperparameter tuning did not improve the performance of the Bernoulli Naive Bayes classifier. This outcome can be attributed to the nature of the Bernoulli Naive Bayes classifier, which is inherently simple and assumes that the features are binary and conditionally independent given the class label. As a result, the classifier's performance is primarily influenced by the quality and relevance of the features rather than the hyperparameters. Therefore, significant improvements through hyperparameter tuning are challenging to achieve for this type of classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction - PCA\n",
    "\n",
    "As we have seen, Naive Bayes classifiers rely heavily on the quality and relevance of the input data. Now, we want to explore whether applying dimensionality reduction through Principal Component Analysis (PCA) can enhance their performance. By reducing the dataset to its most significant components, PCA may improve computational efficiency and potentially boost classifier accuracy. In this analysis, we’ll test if PCA genuinely contributes to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PCA datasets\n",
    "train_pca = pd.read_csv(\"../data/pca/dataset_train_pca.csv\")\n",
    "val_pca = pd.read_csv(\"../data/pca/dataset_val_pca.csv\")\n",
    "test_pca = pd.read_csv(\"../data/pca/dataset_test_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the PCA datasets into features and target\n",
    "X_train_pca = train_pca.drop(columns=[\"Diabetes\"])\n",
    "y_train_pca = train_pca[\"Diabetes\"]\n",
    "\n",
    "X_val_pca = val_pca.drop(columns=[\"Diabetes\"])\n",
    "y_val_pca = val_pca[\"Diabetes\"]\n",
    "\n",
    "X_test_pca = test_pca.drop(columns=[\"Diabetes\"])\n",
    "y_test_pca = test_pca[\"Diabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "nb_classifier = BernoulliNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val_pca)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val_pca, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val_pca, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val_pca)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val_pca, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val_pca, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only best n components for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 5\n",
    "X_train_best_components = X_train_pca.iloc[:, :num_components]\n",
    "X_val_best_components = X_val_pca.iloc[:, :num_components]\n",
    "\n",
    "\n",
    "# Initialize the classifier\n",
    "nb_classifier = BernoulliNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_best_components, y_train_pca)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val_best_components)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val_pca, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val_pca, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only with 5 components or more the classifier does not predict trivially (all no diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "# Function to plot ROC Curve\n",
    "def plot_roc_curve(\n",
    "    nb_classifier, X_train_pca, y_train_pca, X_val_pca, y_val_pca, num_components_list\n",
    "):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for num_components in num_components_list:\n",
    "        # Select the best components\n",
    "        X_train_best_components = X_train_pca.iloc[:, :num_components]\n",
    "        X_val_best_components = X_val_pca.iloc[:, :num_components]\n",
    "\n",
    "        # Train the classifier\n",
    "        nb_classifier.fit(X_train_best_components, y_train_pca)\n",
    "\n",
    "        # Predict probabilities\n",
    "        y_val_prob = nb_classifier.predict_proba(X_val_best_components)[:, 1]\n",
    "\n",
    "        # Compute ROC curve and ROC area\n",
    "        fpr, tpr, _ = roc_curve(y_val_pca, y_val_prob)\n",
    "        roc_auc = roc_auc_score(y_val_pca, y_val_prob)\n",
    "\n",
    "        # Plot ROC curve\n",
    "        plt.plot(fpr, tpr, label=f\"Components: {num_components} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# List of number of components to test\n",
    "num_components_list = [5, 7, 10, 20]\n",
    "\n",
    "# Plot ROC Curve\n",
    "plot_roc_curve(\n",
    "    BernoulliNB(alpha=1),\n",
    "    X_train_pca,\n",
    "    y_train_pca,\n",
    "    X_val_pca,\n",
    "    y_val_pca,\n",
    "    num_components_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
