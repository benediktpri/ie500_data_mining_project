{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing for Diabetes Dataset**\n",
    "\n",
    "In this notebook, we will apply preprocessing steps to the diabetes dataset. The dataset contains various health indicators and a target variable indicating the diabetes status. We will perform the following preprocessing steps:\n",
    "\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "\n",
    "This preprocessing will prepare the data for further analysis and modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Diabetes Dataset Description**\n",
    "This dataset contains 22 features, including 17 categorical features such as 'HighBP', 'HighChol', and 'Smoker', and 4 numerical features like 'BMI', 'Age', 'MentHlth', and 'PhysHlth', with a total of 253680 entries.\n",
    "\n",
    "### Target Variable\n",
    "- **Diabetes_012**\n",
    "    - 0 = no diabetes\n",
    "    - 1 = prediabetes\n",
    "    - 2 = diabetes\n",
    "\n",
    "### Features\n",
    "\n",
    "- **HighBP** (High Blood Pressure)\n",
    "    - 0 = no high BP\n",
    "    - 1 = high BP\n",
    "\n",
    "- **HighChol** (High Cholesterol)\n",
    "    - 0 = no high cholesterol\n",
    "    - 1 = high cholesterol\n",
    "\n",
    "- **CholCheck** (Cholesterol Check)\n",
    "    - 0 = no cholesterol check in 5 years\n",
    "    - 1 = yes cholesterol check in 5 years\n",
    "\n",
    "- **BMI** (Body Mass Index)\n",
    "    - Body Mass Index\n",
    "\n",
    "- **Smoker**\n",
    "    - Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes]\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **Stroke**\n",
    "    - (Ever told) you had a stroke.\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **HeartDiseaseorAttack** (Coronary Heart Disease or Myocardial Infarction)\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **PhysActivity** (Physical Activity)\n",
    "    - Physical activity in past 30 days - not including job\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **Fruits**\n",
    "    - Consume fruit 1 or more times per day\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **Veggies** (Vegetables)\n",
    "    - Consume vegetables 1 or more times per day\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **HvyAlcoholConsump** (Heavy Alcohol Consumption)\n",
    "    - Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week)\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **AnyHealthcare** (Any Health Care Coverage)\n",
    "    - Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc.\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **NoDocbcCost** (No Doctor Because of Cost)\n",
    "    - Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **GenHlth** (General Health)\n",
    "    - Would you say that in general your health is:\n",
    "        - 1 = excellent\n",
    "        - 2 = very good\n",
    "        - 3 = good\n",
    "        - 4 = fair\n",
    "        - 5 = poor\n",
    "\n",
    "- **MentHlth** (Mental Health)\n",
    "    - Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good?\n",
    "    - Scale: 1-30 days\n",
    "\n",
    "- **PhysHlth** (Physical Health)\n",
    "    - Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good?\n",
    "    - Scale: 1-30 days\n",
    "\n",
    "- **DiffWalk** (Difficulty Walking)\n",
    "    - Do you have serious difficulty walking or climbing stairs?\n",
    "    - 0 = no\n",
    "    - 1 = yes\n",
    "\n",
    "- **Sex**\n",
    "    - 0 = female\n",
    "    - 1 = male\n",
    "\n",
    "- **Age**\n",
    "    - 13-level age category (_AGEG5YR see codebook)\n",
    "        -  1 = 18-24\n",
    "        -  2 = 25-29\n",
    "        -  3 = 30-34\n",
    "        -  4 = 35-39\n",
    "        -  5 = 40-44\n",
    "        -  6 = 45-49\n",
    "        -  7 = 50-54\n",
    "        -  8 = 55-59\n",
    "        -  9 = 60-64\n",
    "        - 10 = 65-69\n",
    "        - 11 = 70-74\n",
    "        - 12 = 75-79\n",
    "        - 13 = 80 or older\n",
    "\n",
    "- **Education**\n",
    "    - Education level (EDUCA see codebook)\n",
    "        - 1 = Never attended school or only kindergarten\n",
    "        - 2 = Grades 1 through 8 (Elementary)\n",
    "        - 3 = Grades 9 through 11 (Some high school)\n",
    "        - 4 = Grade 12 or GED (High school graduate)\n",
    "        - 5 = College 1 year to 3 years (Some college or technical school)\n",
    "        - 6 = College 4 years or more (College graduate)\n",
    "\n",
    "- **Income**\n",
    "    - Income scale (INCOME2 see codebook)\n",
    "        - 1 = less than $10,000\n",
    "        - 2 = less than $15,000\n",
    "        - 3 = less than $20,000\n",
    "        - 4 = less than $25,000\n",
    "        - 5 = less than $35,000\n",
    "        - 6 = less than $50,000\n",
    "        - 7 = less than $75,000\n",
    "        - 8 = $75,000 or more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # KBinsDiscretizer\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "\n",
    "from binning import BinningTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"../data/raw/diabetes_012_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Drop rows where the target variable is 1 (prediabetes), rename column and set values to 0, 1 ==> alternative to merge below\n",
    "# df = df[df['Diabetes_012'] != 1]\n",
    "# df = df.rename(columns={'Diabetes_012': 'Diabetes'})\n",
    "# df['Diabetes'] = df['Diabetes'].apply(lambda x: 1 if x == 2 else 0)\n",
    "# df.head()\n",
    "\n",
    "# Merge the classes diabetes and prediabetes for the target variable\n",
    "df[\"Diabetes\"] = df[\"Diabetes_012\"].apply(lambda x: 1 if x == 2 else x)\n",
    "df = df.drop(columns=[\"Diabetes_012\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for different types of features\n",
    "binary_features = [\n",
    "    \"HighBP\",\n",
    "    \"HighChol\",\n",
    "    \"CholCheck\",\n",
    "    \"Smoker\",\n",
    "    \"Stroke\",\n",
    "    \"HeartDiseaseorAttack\",\n",
    "    \"PhysActivity\",\n",
    "    \"Fruits\",\n",
    "    \"Veggies\",\n",
    "    \"HvyAlcoholConsump\",\n",
    "    \"AnyHealthcare\",\n",
    "    \"NoDocbcCost\",\n",
    "    \"DiffWalk\",\n",
    "    \"Sex\",\n",
    "]  # no further preprocessing required\n",
    "ordinal_features = [\n",
    "    \"GenHlth\",\n",
    "    \"Age\",\n",
    "    \"Education\",\n",
    "    \"Income\",\n",
    "]  # no further preprocessing required\n",
    "numerical_features = [\n",
    "    \"MentHlth\",\n",
    "    \"PhysHlth\",\n",
    "]  # will be normalized\n",
    "binned_features = [\"BMI\"]  # will be binned to 0-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for the BMI\n",
    "bin_edges = [0, 18.5, 25, 30, df[\"BMI\"].max() + 1]\n",
    "num_bins = len(bin_edges) - 1\n",
    "labels = list(range(num_bins))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(\"Diabetes\", axis=1)\n",
    "y = df[\"Diabetes\"]\n",
    "\n",
    "# Split data into training, validation and test splits [80%, 10%, 10%] using stratified split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split the temp set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "binning_transformer = BinningTransformer(bins=bin_edges, labels=labels)\n",
    "numerical_pipeline = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_features),\n",
    "        (\"binned\", binning_transformer, binned_features),\n",
    "        (\"binary\", \"passthrough\", binary_features),\n",
    "        (\"ordinal\", \"passthrough\", ordinal_features),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Apply the preprocessing pipeline to the training and testing data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Display the shapes of the preprocessed datasets\n",
    "print(f\"X_train_preprocessed shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"X_val_preprocessed shape: {X_val_preprocessed.shape}\")\n",
    "print(f\"X_test_preprocessed shape: {X_test_preprocessed.shape}\")\n",
    "\n",
    "# Display the shapes of the target variables\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save preprocessed data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preprocessed training and testing sets back into DataFrames with correct column names\n",
    "column_names = numerical_features + binned_features + binary_features + ordinal_features\n",
    "train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=column_names, index=X_train.index)\n",
    "val_preprocessed_df = pd.DataFrame(X_val_preprocessed, columns=column_names, index=X_val.index)\n",
    "test_preprocessed_df = pd.DataFrame(X_test_preprocessed, columns=column_names, index=X_test.index)\n",
    "\n",
    "# Include the y values in datframes\n",
    "train_preprocessed_df[\"Diabetes\"] = y_train.values\n",
    "val_preprocessed_df[\"Diabetes\"] = y_val.values\n",
    "test_preprocessed_df[\"Diabetes\"] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing each dataset into .csv file\n",
    "train_preprocessed_df.to_csv(\"../data/preprocessed/dataset_train.csv\", index=False)\n",
    "val_preprocessed_df.to_csv(\"../data/preprocessed/dataset_val.csv\", index=False)\n",
    "test_preprocessed_df.to_csv(\"../data/preprocessed/dataset_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to load data with data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train, y_train = data_loader.training_data\n",
    "X_val, y_val = data_loader.validation_data\n",
    "X_test, y_test = data_loader.test_data\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to load data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "train_df = data_loader.training_dataframe\n",
    "val_df = data_loader.validation_dataframe\n",
    "test_df = data_loader.test_dataframe\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=None)  # n_components=None means that all components will be kept\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Retrieve the eigenvectors (components)\n",
    "eigenvectors = pca.components_\n",
    "\n",
    "# Retrieve the eigenvalues (explained variance)\n",
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing and Plotting the variance ratio of each principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp = 1\n",
    "for ratio in pca.explained_variance_ratio_:\n",
    "    comp = \"Component No. \"\n",
    "    text = comp + str(num_comp) + \":\"\n",
    "\n",
    "    print(\"Ratio of\", text, ratio)\n",
    "    num_comp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(\n",
    "    x=[i + 1 for i in range(len(pca.explained_variance_ratio_))],\n",
    "    y=pca.explained_variance_ratio_,\n",
    "    s=200,\n",
    "    alpha=0.75,\n",
    "    c=\"orange\",\n",
    "    edgecolor=\"k\",\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.title(\"Explained variance ratio of the \\nfitted principal component vector\\n\", fontsize=25)\n",
    "plt.xlabel(\"Principal components\", fontsize=15)\n",
    "plt.xticks([i + 1 for i in range(len(pca.explained_variance_ratio_))], fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel(\"Explained variance ratio\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot illustrates that the $1^{st}$ principle component explains about 47% of the total variance in the data and the $2^{nd}$ component explains further 24%. This means that only the first two components already explain about 71% of the total variance and the remaining 19 components only 29%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca_df = pd.DataFrame(data=X_train_pca)\n",
    "x_train_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get unique classes and map each class to a specific level for better visualization\n",
    "unique_classes = np.unique(y_train)\n",
    "class_levels = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "# Create new levels for each class for better separation in 1D plots\n",
    "y_levels_pc1 = [class_levels[cls] for cls in y_train]  # Y-levels for PC1\n",
    "x_levels_pc2 = [class_levels[cls] for cls in y_train]  # X-levels for PC2\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 2D scatter plot for the first two principal components\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(\n",
    "    x_train_pca_df[0],\n",
    "    x_train_pca_df[1],\n",
    "    c=y_train,\n",
    "    edgecolors=\"k\",\n",
    "    alpha=0.75,\n",
    "    s=150,\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.title(\"Class separation using first two principal components\\n\", fontsize=20)\n",
    "plt.xlabel(\"Principal component-1\", fontsize=15)\n",
    "plt.ylabel(\"Principal component-2\", fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Principal Components as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert remaining  principal components splits into DataFrames\n",
    "train_pca_df = x_train_pca_df\n",
    "val_pca_df = pd.DataFrame(data=X_val_pca)\n",
    "test_pca_df = pd.DataFrame(data=X_test_pca)\n",
    "\n",
    "# Include the y values in datframes\n",
    "train_pca_df[\"Diabetes\"] = y_train\n",
    "val_pca_df[\"Diabetes\"] = y_val\n",
    "test_pca_df[\"Diabetes\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing each dataset into .csv file\n",
    "train_pca_df.to_csv(\"../data/pca/dataset_train_pca.csv\", index=False)\n",
    "val_pca_df.to_csv(\"../data/pca/dataset_val_pca.csv\", index=False)\n",
    "test_pca_df.to_csv(\"../data/pca/dataset_test_pca.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to load data with data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca shape: (202944, 3)\n",
      "y_train_pca shape: (202944,)\n",
      "X_val_pca shape: (25368, 3)\n",
      "y_val_pca shape: (25368,)\n",
      "X_test_pca shape: (25368, 3)\n",
      "y_test_pca shape: (25368,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train_pca, y_train_pca = data_loader.training_data_pca(n=3) # if no n is given all components will be returned\n",
    "X_val_pca, y_val_pca = data_loader.validation_data_pca(3)\n",
    "X_test_pca, y_test_pca = data_loader.test_data_pca(3)\n",
    "\n",
    "print(f\"X_train_pca shape: {X_train_pca.shape}\")\n",
    "print(f\"y_train_pca shape: {y_train_pca.shape}\")\n",
    "print(f\"X_val_pca shape: {X_val_pca.shape}\")\n",
    "print(f\"y_val_pca shape: {y_val_pca.shape}\")\n",
    "print(f\"X_test_pca shape: {X_test_pca.shape}\")\n",
    "print(f\"y_test_pca shape: {y_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to load data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.079228</td>\n",
       "      <td>0.569142</td>\n",
       "      <td>0.829476</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.446370</td>\n",
       "      <td>1.760168</td>\n",
       "      <td>1.215792</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.714603</td>\n",
       "      <td>-2.786327</td>\n",
       "      <td>1.044002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.475631</td>\n",
       "      <td>-3.902256</td>\n",
       "      <td>1.998963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.499275</td>\n",
       "      <td>2.595663</td>\n",
       "      <td>-0.986308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2  Diabetes\n",
       "0  5.079228  0.569142  0.829476       1.0\n",
       "1 -0.446370  1.760168  1.215792       0.0\n",
       "2  0.714603 -2.786327  1.044002       0.0\n",
       "3 -3.475631 -3.902256  1.998963       0.0\n",
       "4  4.499275  2.595663 -0.986308       0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "train_df_pca = data_loader.training_dataframe_pca(3)\n",
    "val_df_pca = data_loader.validation_dataframe_pca(3)\n",
    "test_df_pca = data_loader.test_dataframe_pca(3)\n",
    "\n",
    "train_df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over- and Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply random oversampling to training set\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(f\"X_resampled shape: {X_oversampled.shape}\")\n",
    "print(f\"y_resampled shape: {y_oversampled.shape}\")\n",
    "\n",
    "# Show class distributions\n",
    "print(\"\\nClass distribution before oversampling:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "print(y_oversampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preprocessed resampled training set back into DataFrame with correct column names\n",
    "train_preprocessed_oversampled_df = pd.DataFrame(X_oversampled, columns=column_names)\n",
    "\n",
    "# Include the y values in the dataframe\n",
    "train_preprocessed_oversampled_df[\"Diabetes\"] = y_oversampled.values\n",
    "\n",
    "# Storing each dataset into .csv file\n",
    "train_preprocessed_oversampled_df.to_csv(\n",
    "    \"../data/resampling/dataset_train_oversampled.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply synthetic oversampling with SMOTE to training set\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_oversampled_smote, y_oversampled_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"X_resampled shape: {X_oversampled_smote.shape}\")\n",
    "print(f\"y_resampled shape: {y_oversampled_smote.shape}\")\n",
    "\n",
    "# Show class distributions\n",
    "print(\"\\nClass distribution before oversampling:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "print(y_oversampled_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preprocessed resampled training set back into DataFrame with correct column names\n",
    "train_preprocessed_oversampled_smote_df = pd.DataFrame(X_oversampled_smote, columns=column_names)\n",
    "\n",
    "# Include the y values in the dataframe\n",
    "train_preprocessed_oversampled_smote_df[\"Diabetes\"] = y_oversampled_smote.values\n",
    "\n",
    "# Storing each dataset into .csv file\n",
    "train_preprocessed_oversampled_smote_df.to_csv(\n",
    "    \"../data/resampling/dataset_train_oversampled_smote.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply random undersampling to training set\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(f\"X_resampled shape: {X_undersampled.shape}\")\n",
    "print(f\"y_resampled shape: {y_undersampled.shape}\")\n",
    "\n",
    "# Show class distributions\n",
    "print(\"\\nClass distribution before undersampling:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after undersampling:\")\n",
    "print(y_undersampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preprocessed resampled training set back into DataFrame with correct column names\n",
    "train_preprocessed_undersampled_df = pd.DataFrame(X_undersampled, columns=column_names)\n",
    "\n",
    "# Include the y values in the dataframe\n",
    "train_preprocessed_undersampled_df[\"Diabetes\"] = y_undersampled.values\n",
    "\n",
    "# Storing each dataset into .csv file\n",
    "train_preprocessed_undersampled_df.to_csv(\n",
    "    \"../data/resampling/dataset_train_undersampled.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to load data with data_loader.py\n",
    "\n",
    "Note that when using resampling one should still use the unbalanced validation and test splits as these should represent the original, real-world distribution of the data.\n",
    "\n",
    "Example shown for random under-sampling: `training_data_undersampling_random`. You can also use `training_data_oversampling_random` and `training_data_oversampling_smote`, as well as load a dataframe similar as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader()\n",
    "X_train_undersampling_random, y_train_undersampling_random = (\n",
    "    data_loader.training_data_undersampling_random\n",
    ")\n",
    "X_val, y_val = data_loader.validation_data\n",
    "X_test, y_test = data_loader.test_data\n",
    "\n",
    "print(f\"X_train_undersampling_random shape: {X_train_undersampling_random.shape}\")\n",
    "print(f\"y_train_undersampling_random shape: {y_train_undersampling_random.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
